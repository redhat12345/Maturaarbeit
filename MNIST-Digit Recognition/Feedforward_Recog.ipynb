{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit recognition with a normal feedforward NN\n",
    "\n",
    "All credits to: https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py. \n",
    "The following code is a modified version of the above. The error rate is about 0.9% after 10 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 760 (CNMeM is enabled with initial size: 40.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_pixels is equal to **748**\n",
    "\n",
    "X_train will have the shape **(60000, 748)**\n",
    "\n",
    "X_test  will have the shape **(10000, 748)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot-encode outputs (Bsp: 2 --> [0,0,1,0,0,0,0,0,0,0])\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot-encoding is used because in the network, there is one neuron for one number...\n",
    "\n",
    "To predict the networks output, one takes the index of the most active neuron and thereby converts the one-hot-vector back into a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "\t# Create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'softmax' is a sigmoid shaped curve\n",
    "\n",
    "'categorical_crossentropy' is the used loss-function or error-function\n",
    "\n",
    "'adam' is the specified way of performing gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 0.2772 - acc: 0.9218 - val_loss: 0.1385 - val_acc: 0.9591\n",
      "Epoch 2/10\n",
      "0s - loss: 0.1129 - acc: 0.9670 - val_loss: 0.1058 - val_acc: 0.9669\n",
      "Epoch 3/10\n",
      "0s - loss: 0.0737 - acc: 0.9786 - val_loss: 0.0744 - val_acc: 0.9773\n",
      "Epoch 4/10\n",
      "0s - loss: 0.0508 - acc: 0.9850 - val_loss: 0.0742 - val_acc: 0.9764\n",
      "Epoch 5/10\n",
      "0s - loss: 0.0375 - acc: 0.9890 - val_loss: 0.0649 - val_acc: 0.9805\n",
      "Epoch 6/10\n",
      "0s - loss: 0.0276 - acc: 0.9928 - val_loss: 0.0682 - val_acc: 0.9770\n",
      "Epoch 7/10\n",
      "0s - loss: 0.0205 - acc: 0.9946 - val_loss: 0.0607 - val_acc: 0.9809\n",
      "Epoch 8/10\n",
      "0s - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0621 - val_acc: 0.9811\n",
      "Epoch 9/10\n",
      "0s - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0685 - val_acc: 0.9785\n",
      "Epoch 10/10\n",
      "0s - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0619 - val_acc: 0.9809\n",
      "Error: 1.91%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
